{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data encoding and decoding \n",
    "## Part 2 of the series of notebooks to solve the competition\n",
    "\n",
    "\n",
    "## Content:\n",
    "  - [Import required modules](#Import%20required%20modules)\n",
    "  - [load data](#load%20data)\n",
    "  - [Data cleaning](#Data cleaning)\n",
    "  - [Encoding](#Encoding)\n",
    "  - [Decoding](#Decoding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter majec function to print images inlined\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "from nltk.corpus import stopwords # load stoping words\n",
    "from nltk.tokenize import word_tokenize # word tokenizer\n",
    "import pickle # to save clean data\n",
    "from itertools import chain \n",
    "import re # Regular expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = 'dataset'\n",
    "\n",
    "#Training data\n",
    "train = pd.read_csv(dataPath+'/train.csv')\n",
    "# Testing data \n",
    "test = pd.read_csv(dataPath+'/test.csv')\n",
    "\n",
    "for col in train.columns:\n",
    "    train[col] = train[col].astype(str)\n",
    "for col in test.columns:\n",
    "    test[col] = test[col].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished cleaning\n"
     ]
    }
   ],
   "source": [
    "def get_char_only(text):\n",
    "    chars = re.compile(r\"[^a-zA-Z]\")\n",
    "    return chars.sub(r' ',text)\n",
    "\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    text=html.sub(r'',text)\n",
    "    return text\n",
    "    \n",
    "def remove_stoping_words(text):\n",
    "    stop=set(stopwords.words('english'))\n",
    "    return \" \".join([x for x in word_tokenize(text) if x not in stop])\n",
    "\n",
    "# def remove_stoping_words(data):\n",
    "#     return [ remove_stopwords_statment(i) for i in data]\n",
    "\n",
    "def remove_emoji(text): \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def remove_tag(text):\n",
    "    return ' '.join(re.sub(\"[@][\\w_-]+\",\" \",text).split())\n",
    "\n",
    "def strp(text):\n",
    "    return text.strip()\n",
    "\n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def clean_data(data): # data must by list only\n",
    "    data= data.apply(lambda x : remove_html(x))\n",
    "    data= data.apply(lambda x : remove_URL(x))\n",
    "    data= data.apply(lambda x : remove_emoji(x))\n",
    "    data= data.apply(lambda x : remove_tag(x))\n",
    "    data= data.apply(lambda x : get_char_only(x))\n",
    "    data= data.apply(lambda x : remove_stoping_words(x))    \n",
    "    return data\n",
    "\n",
    "def clean_train():\n",
    "    train_df=train.copy()\n",
    "    train_df.text=clean_data(data=train.text)\n",
    "    train_df.selected_text=clean_data(train.selected_text)\n",
    "    return train_df\n",
    "    \n",
    "def clean_test():\n",
    "    test_df=test.copy()\n",
    "    test_df.text=clean_data(test.text)\n",
    "    return test_df\n",
    "    \n",
    "train_clean = clean_train()\n",
    "test_clean = clean_test()\n",
    "\n",
    "print(\"Finished cleaning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "\n",
    "We currently use char one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 256)\n",
      "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "lst1=np.array([1,2,5,6])\n",
    "\n",
    "oneHotBase=np.zeros(256)\n",
    "def oneHot(i):\n",
    "    cop=np.copy(oneHotBase)\n",
    "    cop[i]=1\n",
    "    return cop \n",
    "chr2vec={chr(i): oneHot(i) for i in range(256)}\n",
    "\n",
    "def fun(i):\n",
    "    return tuple(4*i + j for j in range(4))\n",
    "\n",
    "st=\"abc\"\n",
    "\n",
    "print(np.array([chr2vec[st[x]] for x in range(len(st))]).shape)\n",
    "\n",
    "a = np.fromiter(chain.from_iterable(chr2vec[st[x]] for x in range(len(st))), 'i', len(st) * 256)\n",
    "a.shape = len(\"abc\"), 256\n",
    "\n",
    "print(repr(a))\n",
    "\n",
    "# c= (np.array(x) for x in range(5)) #(chr2vec[x] for x in \"abc\")\n",
    "# lst2= np.fromiter(c, type(np.array))\n",
    " \n",
    "# np.empty((2,4), int) # (text, 265)\n",
    "# for i in [0,1]:\n",
    "#     lst2[i]=lst1\n",
    "# lst2[0][0]=0\n",
    "# lst2= np.hstack(lst2, lst1)\n",
    "# np.concatenate((lst2, lst1), axis=0)\n",
    "# iterable = (lst1.copy() for x in range(3))\n",
    "# lst2 = np.fromiter(iterable, np.ndarray)\n",
    "\n",
    "# print(type(lst1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished encoding\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a3d0a7d5ad</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>my boss was not happy w/ them. Lots of fun.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251b6a6766</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>Good</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c9e8d1ef1c</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>says good (or should i say bad?) afternoon!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f14f087215</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>i dont think you can vote anymore!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bf7473b12d</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>better</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  a3d0a7d5ad  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "1  251b6a6766  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "2  c9e8d1ef1c  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "3  f14f087215  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "4  bf7473b12d  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "\n",
       "                                 selected_text sentiment  \n",
       "0  my boss was not happy w/ them. Lots of fun.   neutral  \n",
       "1                                         Good  positive  \n",
       "2  says good (or should i say bad?) afternoon!   neutral  \n",
       "3           i dont think you can vote anymore!  negative  \n",
       "4                                       better  positive  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneHotBase=np.zeros(256)\n",
    "def oneHot(i):\n",
    "    cop=np.copy(oneHotBase)\n",
    "    cop[i]=1\n",
    "    return cop \n",
    "chr2vec={chr(i): oneHot(i) for i in range(256)}\n",
    "\n",
    "def encode(text):\n",
    "    ln = len(text)\n",
    "    a= np.fromiter(chain.from_iterable(chr2vec[text[x2]] for x2 in range(len(text))), 'i', len(text) * 256)\n",
    "    a.shape = len(text), 256\n",
    "    \n",
    "#     a= np.empty((ln, 256), int) # (text, 265)\n",
    "#     for i in range(ln):\n",
    "#         a[i]=chr2vec[text[i]]\n",
    "#         [chr2vec[text[i]] for i in range(ln)]\n",
    "#     x = np.zeros((256-len(text),256)) #(text,256)\n",
    "    \n",
    "    return a #np.concatenate((a, x), axis=0)\n",
    "\n",
    "\n",
    "train_encoded=train.copy()\n",
    "train_encoded.text=train.text.apply(lambda x:encode(x))\n",
    "# train_encoded.selected_text=train.selected_text.apply(lambda x:encode(x))\n",
    "\n",
    "# train_clean_encoded=train_clean.copy()\n",
    "# train_clean_encoded.text=train_clean.text.apply(lambda x:encode(x))\n",
    "# train_clean_encoded.text=train_clean.text.apply(lambda x:encode(x))\n",
    "# train_clean_encoded.selected_text=train_clean.selected_text.apply(lambda x:encode(x))\n",
    "\n",
    "# test_encoded=test.copy()\n",
    "# test_encoded.text=test.text.apply(lambda x:encode(x))\n",
    "\n",
    "# test_clean_encoded=test_clean.copy()\n",
    "# test_clean_encoded.text=test_clean.text.apply(lambda x:encode(x))\n",
    "\n",
    "print(\"Finished encoding\")\n",
    "train_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_clean_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-1462e06c65ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_chr_encoded\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_clean_chr_encoded\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_clean_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_chr_encoded\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_clean_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "def save(name,obj):\n",
    "    pickleOut= open(\"dataset/pickled/\"+name,\"wb\")\n",
    "    pickle.dump(obj,pickleOut)\n",
    "    pickleOut.close()\n",
    "    \n",
    "save(\"train_chr_encoded\",train_encoded)\n",
    "save(\"train_clean_chr_encoded\",train_clean_encoded)\n",
    "\n",
    "save(\"test_chr_encoded\",test_encoded)\n",
    "save(\"test_clean_chr_encoded\",test_clean_encoded)\n",
    "\n",
    "print(\"Finished pickling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load other data\n",
    "# pickleIn = open(path+name,\"rb\")\n",
    "# obj = pickle.load(pickleIn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-27f026b7536a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Decode(train_encoded.text[0]) is: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvecs2String\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-27f026b7536a>\u001b[0m in \u001b[0;36mvecs2String\u001b[0;34m(lst)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvecs2String\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0moneHotBase\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mstring\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mvec2Chr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "def vec2Chr(lst):\n",
    "    for x in range(len(lst)): \n",
    "        if lst[x] == 1: return chr(x)\n",
    "\n",
    "def vecs2String(lst):\n",
    "    string=\"\"\n",
    "    for i in lst:\n",
    "        if i == oneHotBase: break\n",
    "        string+=vec2Chr(i)\n",
    "    return string\n",
    "\n",
    "print(\"Decode(train_encoded.text[0]) is: \\n\",vecs2String(train_encoded.text[0]))\n",
    "print(\"=================\")\n",
    "\n",
    "\n",
    "do_assert = 1\n",
    "if do_assert:\n",
    "    assert(vec2Chr(chr2vec['a']) == 'a') \n",
    "    assert(vecs2String(train_encoded.text[0]) == train.text[0]) \n",
    "    \n",
    "print(\"Finished decoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda239802d5b05944f39cc87e8ae17a5fc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
