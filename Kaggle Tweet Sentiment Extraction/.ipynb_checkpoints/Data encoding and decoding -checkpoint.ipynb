{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data encoding and decoding \n",
    "## Part 2 of the series of notebooks to solve the competition\n",
    "\n",
    "\n",
    "## Content:\n",
    "  - [Import required modules](#Import%20required%20modules)\n",
    "  - [load data](#load%20data)\n",
    "  - [Data cleaning](#Data cleaning)\n",
    "  - [Encoding](#Encoding)\n",
    "  - [Decoding](#Decoding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter majec function to print images inlined\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "from nltk.corpus import stopwords # load stoping words\n",
    "from nltk.tokenize import word_tokenize # word tokenizer\n",
    "import pickle # to save clean data\n",
    "\n",
    "import re # Regular expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = 'dataset'\n",
    "\n",
    "#Training data\n",
    "train = pd.read_csv(dataPath+'/train.csv')\n",
    "# Testing data \n",
    "test = pd.read_csv(dataPath+'/test.csv')\n",
    "\n",
    "for col in train.columns:\n",
    "    train[col] = train[col].astype(str)\n",
    "for col in test.columns:\n",
    "    test[col] = test[col].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished cleaning\n"
     ]
    }
   ],
   "source": [
    "def get_char_only(text):\n",
    "    chars = re.compile(r\"[^a-zA-Z]\")\n",
    "    return chars.sub(r' ',text)\n",
    "\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    text=html.sub(r'',text)\n",
    "    return text\n",
    "    \n",
    "def remove_stoping_words(text):\n",
    "    stop=set(stopwords.words('english'))\n",
    "    return \" \".join([x for x in word_tokenize(text) if x not in stop])\n",
    "\n",
    "# def remove_stoping_words(data):\n",
    "#     return [ remove_stopwords_statment(i) for i in data]\n",
    "\n",
    "def remove_emoji(text): \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def remove_tag(text):\n",
    "    return ' '.join(re.sub(\"[@][\\w_-]+\",\" \",text).split())\n",
    "\n",
    "def strp(text):\n",
    "    return text.strip()\n",
    "\n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def clean_data(data): # data must by list only\n",
    "    data= data.apply(lambda x : remove_html(x))\n",
    "    data= data.apply(lambda x : remove_URL(x))\n",
    "    data= data.apply(lambda x : remove_emoji(x))\n",
    "    data= data.apply(lambda x : remove_tag(x))\n",
    "    data= data.apply(lambda x : get_char_only(x))\n",
    "    data= data.apply(lambda x : remove_stoping_words(x))    \n",
    "    return data\n",
    "\n",
    "def clean_train():\n",
    "    train_df=train.copy()\n",
    "    train_df.text=clean_data(data=train.text)\n",
    "    train_df.selected_text=clean_data(train.selected_text)\n",
    "    return train_df\n",
    "    \n",
    "def clean_test():\n",
    "    test_df=test.copy()\n",
    "    test_df.text=clean_data(test.text)\n",
    "    return test_df\n",
    "    \n",
    "train_clean = clean_train()\n",
    "test_clean = clean_test()\n",
    "\n",
    "print(\"Finished cleaning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "\n",
    "We currently use char one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished encoding\n"
     ]
    }
   ],
   "source": [
    "oneHotBase=np.zeros(265)\n",
    "def oneHot(i):\n",
    "    cop=oneHotBase.copy()\n",
    "    cop[i]=1\n",
    "    return cop \n",
    "chr2vec={chr(i): oneHot(i) for i in range(256)}\n",
    "\n",
    "def encode(text):\n",
    "    return [chr2vec[i] for i in text]\n",
    "\n",
    "train_encoded=train.copy()\n",
    "train_encoded.text=train.text.apply(lambda x:encode(x))\n",
    "train_encoded.selected_text=train.selected_text.apply(lambda x:encode(x))\n",
    "\n",
    "train_clean_encoded=train_clean.copy()\n",
    "train_clean_encoded.text=train_clean.text.apply(lambda x:encode(x))\n",
    "train_clean_encoded.text=train_clean.text.apply(lambda x:encode(x))\n",
    "train_clean_encoded.selected_text=train_clean.selected_text.apply(lambda x:encode(x))\n",
    "\n",
    "test_encoded=test.copy()\n",
    "test_encoded.text=test.text.apply(lambda x:encode(x))\n",
    "\n",
    "test_clean_encoded=test_clean.copy()\n",
    "test_clean_encoded.text=test_clean.text.apply(lambda x:encode(x))\n",
    "\n",
    "print(\"Finished encoding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished pickling\n"
     ]
    }
   ],
   "source": [
    "def save(name,obj):\n",
    "    pickleOut= open(\"dataset/pickled/\"+name,\"wb\")\n",
    "    pickle.dump(obj,pickleOut)\n",
    "    pickleOut.close()\n",
    "    \n",
    "save(\"train_chr_encoded\",trein_encoded)\n",
    "save(\"train_clean_chr_encoded\",trein_clean_encoded)\n",
    "\n",
    "save(\"test_chr_encoded\",test_encoded)\n",
    "save(\"test_clean_chr_encoded\",test_clean_encoded)\n",
    "\n",
    "print(\"Finished pickling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load other data\n",
    "# pickleIn = open(path+name,\"rb\")\n",
    "# obj = pickle.load(pickleIn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode(train_encoded.text[0]) is: \n",
      " Spent the entire morning in a meeting w/ a vendor, and my boss was not happy w/ them. Lots of fun.  I had other plans for my morning\n",
      "=================\n",
      "Finished decoding\n"
     ]
    }
   ],
   "source": [
    "def vec2Chr(lst):\n",
    "    for x in range(len(lst)): \n",
    "        if lst[x] == 1: return chr(x)\n",
    "\n",
    "def vecs2String(lst):\n",
    "    string=\"\"\n",
    "    for i in lst:\n",
    "        string+=vec2Chr(i)\n",
    "    return string\n",
    "\n",
    "print(\"Decode(train_encoded.text[0]) is: \\n\",vecs2String(train_encoded.text[0]))\n",
    "print(\"=================\")\n",
    "\n",
    "\n",
    "do_assert = 1\n",
    "if do_assert:\n",
    "    assert(vec2Chr(chr2vec['a']) == 'a') \n",
    "    assert(vecs2String(train_encoded.text[0]) == train.text[0]) \n",
    "    \n",
    "print(\"Finished decoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda239802d5b05944f39cc87e8ae17a5fc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
